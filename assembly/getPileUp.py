"""
Created on Thurs Oct 25 17:07:36 2017

@author: nolln - adapted from neherr and zaninif

Purpose of this file is to convert bam files generated by mapping illumina data 
onto the assembled contigs/reference geneome into pileups.

Required packages
    1. pysam
    2. numpy
"""

import pysam
import numpy as np
from collections import defaultdict

def performPileUp( bamFile, QC=False, pairedEnd=False, qual_min=30, illumina=True ):
    if (illumina):
        alphabet = np.fromstring('ACGT-N', dtype='S1')
        align = pysam.AlignmentFile(bamFile,"rb")
        # Allocate space for pileup
        totCov = []
        for nContig in xrange(align.nreferences):
            totCov.append( [align.getrname(nContig),
                            returnPileupStructure(align.lengths[nContig],QC,pairedEnd),
                            returnInsertionStructure(QC,pairedEnd)] )

        # Iterate over reads in BAM file
        nUnmapped = 0
        for n, read in enumerate(align):
            if (read.seq is not None):
                if (not read.is_unmapped):
                    if (QC):
                        rev = int(read.is_reverse)
                        if (pairedEnd):
                            r1 = int(read.is_read2)
                            counts = totCov[read.rname][1][r1,rev]
                        else:
                            counts = totCov[read.rname][1][rev]
                    else:
                        counts = totCov[read.rname][1]
                    
                    insertion = totCov[read.rname][2]

                    seq = np.fromstring(read.seq,'S1')
                    if (read.qual is not None):
                        qual = np.fromstring(read.qual,np.int8) - 33
                    else:
                        qual = 60*np.ones(len(seq))
                    pos = read.pos
                    
                    # Iterate over block types within the CIGAR code
                    for ic, (block_type, block_len) in enumerate(read.cigar):
                        if (block_type == 4): # Soft clip
                            seq = seq[block_len:]
                            qual = qual[block_len:]
                        
                        if (block_type == 0): # Normal
                            seqb = seq[:block_len]
                            qualb = qual[:block_len]
                            for j, a in enumerate(alphabet): # Increment nucleotide counts from read
                                posa = ((seqb==a) & (qualb >= qual_min)).nonzero()[0]
                                if len(posa):
                                    counts[j,pos+posa] += 1
                                        
                            if ic != len(read.cigar) - 1: # Move along sequence
                                seq = seq[block_len:]
                                qual = qual[block_len:]
                                pos += block_len
                                
                        elif (block_type == 2): # Deletion
                            counts[4,pos:pos+block_len] += 1
                            pos += block_len #Advance reference but not read
                            
                        elif (block_type == 1): # Insertion
                            seqb = seq[:block_len]
                            qualb = qual[:block_len]
                            # Accept only high-quality inserts
                            if (qualb >= qual_min).all():
                                if (QC):
                                    if pairedEnd:
                                        insertion[pos][seqb.tostring()][r1, rev] += 1
                                    else:
                                        insertion[pos][seqb.tostring()][rev] += 1
                                else:
                                    insertion[pos][seqb.tostring()] += 1
                                    
                            # Chop off seq, but not pos
                            if ic != len(read.cigar) - 1:
                                seq = seq[block_len:]
                                qual = qual[block_len:]
                else:
                    nUnmapped += 1
        fracUnmapped = (nUnmapped) / (1. * n)  
    else:
        align = pysam.AlignmentFile(bamFile,"rb")
        # alphabet = np.fromstring('ACGT-N', dtype='S1')
        alphabet = { 'A':0,'C':1,'G':2,'T':3,'-':4,'N':5 }
        contig_len = align.lengths
        totCov = []
        for n,ref in enumerate(align.references):
            pileup = align.pileup(ref)
            counts = np.zeros( (6,contig_len[n]) )
            for l,column in enumerate(pileup):
                for read in column.pileups:
                    row = read.alignment
                    if (read.is_del):
                        counts[4,l] += 1
                    else:
                        counts[alphabet[row.seq[read.query_position]],l] += 1
            totCov.append( (align.getrname(n),counts,[]) )

        numUnmapped = 0
        # for n, read in enumerate(align):
        #     if (read.is_unmapped):
        #         numUnmapped += 1

        fracUnmapped = (1. * numUnmapped) / n

    return totCov, fracUnmapped
    
def returnPileupStructure( N, QC, pairedEnd ):
    if (not QC):
        return np.zeros((6,N))
    else:
        if (pairedEnd):
            return np.zeros((2,2,6,N))
        else:
            return np.zeros((2,6,N))
        
def returnInsertionStructure( QC, paired ):
    if QC:
        if paired:
            return defaultdict(lambda: defaultdict(lambda: np.zeros((2,2),int)))
        else:
            return defaultdict(lambda: defaultdict(lambda: np.zeros(2,int)))
    else:
        return defaultdict(lambda: defaultdict(lambda: np.zeros(1,int)))

def basicVariantCall( pileUp, ref=None ):
    # This function will serve as a basic variant call method to be used in
    # our single ref. pipelines. It will remove all singleton sites (with
    # no mapping ambiguity).

    from Bio.Seq import Seq
    from Bio import SeqIO
    from Bio.Alphabet import SingleLetterAlphabet
    from itertools import izip
    from scipy.stats import iqr
    # import numpy as np

    mapQC = []
    summaryStats = []
    consensusContigs = []
    variants = []

    for refName,counts,inserts in pileUp:
        outName = refName.split("|")[-1].replace('/','_')
        tmpDict = defaultdict(list)
        tmpDict2 = defaultdict(int)
        
        tmpDict['name'] = outName
        tmpDict['variant'] = [np.nonzero(counts[:,n])[0].tolist() for n in xrange(counts.shape[1])]
        tmpDict['cov'] = [counts[np.nonzero(counts[:,n])[0],n].tolist() for n in xrange(counts.shape[1])]

        siteCov = np.sum(counts,axis=0)
        tmpDict2['avg_cov'] = np.median( siteCov )
        tmpDict2['std_cov'] = (20.0*iqr( siteCov )) / 27.0
        tmpDict2['num_uncov'] = np.sum(siteCov == 0)
        tmpDict2['contig_len'] = len(siteCov) 

        frac = counts[:,siteCov>0]
        frac /= (1.*frac.sum(axis=0,keepdims=True))
        # print np.sum(frac.sum(axis=0,keepdims=True) ==0)
        S = -np.log(frac+.0001) * frac
        tmpDict2['site_entropy'] = np.mean(np.sum(S,axis=0)) 

        serialIndel = inserts
        for outKey in serialIndel.keys():
            for inKey in serialIndel[outKey].keys():
                serialIndel[outKey][inKey] = np.asscalar(serialIndel[outKey][inKey])

        tmpDict['indel'] = serialIndel
        mapQC.append(tmpDict)
        summaryStats.append(tmpDict2)
        # Save consensus sequence (where it differs from reference) as well as locations where variation
        # has been detected.
        consensusSeq = []
        variableSites = defaultdict(lambda: defaultdict(list))
        alphabet = {0: 'A', 1: 'C', 2: 'G', 3: 'T', 4: '-', 5: 'N'}

        for n,seq in enumerate(tmpDict['variant']):
            if (len(seq) > 1):
                variableSites[n]['nuc'] = [alphabet[s] for s in seq]
                variableSites[n]['cov'] = tmpDict['cov'][n] # If there are more than one detected variant, store
                consensusSeq.append(alphabet[seq[np.argmax(tmpDict['cov'][n])]])
            elif (len(seq) == 0):
                consensusSeq.append('-')
            else:
                consensusSeq.append(alphabet[seq[0]])
        consensusContigs.append(Seq(''.join(consensusSeq),SingleLetterAlphabet()))
        variants.append(variableSites)

    # refSeq = []
    # with open(ref,'r') as refFile:
    #     for contig in SeqIO.parse(refFile,'fasta'):
    #         refSeq.append(contig.seq)

    # Store consensus sequence (as a variant of the reference to save space)
    conSeq = defaultdict(str)
    # for C in xrange(len(refSeq)):
    #     for n,(rN,cN) in enumerate(izip(refSeq[C],consensusContigs[C])):
    #         if (cN != 'N' and rN != cN):
    #             conSeq[n] = cN

    return mapQC,summaryStats,variants,conSeq
        
def savePileUp( pileUp, unmapped, dirName='./pileUp/' ):
    import json
    
    dirName = dirName.rstrip('/')+'/'
    # ref = '/scicore/home/neher/nolln/genomeEvo/community/F113reference.fasta'

    storePileUp,summaryStats,variants,conSeq = basicVariantCall(pileUp) #,ref)
    
    with open(dirName+'pileUp.json','w+') as pUp, \
         open(dirName+'variants.json','w+') as vcf,\
         open(dirName+'consensus.json','w+') as con,\
         open(dirName+'summary.json','w+') as sumry,\
         open(dirName+'unmapped.txt','w+') as txt:
        json.dump(storePileUp, pUp)
        json.dump(variants, vcf)
        json.dump(conSeq, con)
        json.dump(summaryStats, sumry)
        txt.write(str(unmapped))

if __name__== '__main__':
    import sys
    bamFile = sys.argv[1]
    outDir = sys.argv[2]

    if (sys.argv[3]=="1"):
        illumina = True
    else:
        illumina = False

    print bamFile
    print outDir 

    # bamFile = outDir + 'mappedIllumina.bam'
    pileUp,unmapped = performPileUp(bamFile,qual_min=0,illumina=illumina)
    savePileUp(pileUp, unmapped, outDir)
